{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "trained-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from transformers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compliant-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aware-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naval-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n"
     ]
    }
   ],
   "source": [
    "for i,rev in enumerate(df.sample(n = 5000, replace = False)[\"review\"]):\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    sents = list()\n",
    "    doc=nlp(rev, disable = [\"ner\", \"tagger\"])\n",
    "    for j,sent in enumerate(doc.sents):\n",
    "        sents.append(sent)\n",
    "    explore_data.append(sents)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "suspended-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = list()\n",
    "for l in explore_data:\n",
    "    lengths.append(len(l))\n",
    "lengths\n",
    "plt.hist(lengths, range=(0,50), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "assigned-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "22000\n",
      "22500\n",
      "23000\n",
      "23500\n",
      "24000\n",
      "24500\n"
     ]
    }
   ],
   "source": [
    "train_mini = list()\n",
    "for i,rev in enumerate(df[\"review\"][:25000]):\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    sents = list()\n",
    "    doc=nlp(rev, disable = [\"ner\", \"tagger\"])\n",
    "    for j,sent in enumerate(doc.sents):\n",
    "        if j == 10: # avg length of sents\n",
    "            break\n",
    "        sents.append(str(sent))\n",
    "    train_mini.append(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "alternate-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    clean_data = list()\n",
    "    for review in data:\n",
    "        clean_sents = list()\n",
    "        for sent in review:\n",
    "            doc = nlp(sent, disable = [\"ner\", \"parser\", \"tagger\"])\n",
    "            tokens = list()\n",
    "            for token in doc:\n",
    "                if token.is_alpha and not token.is_stop and len(token.text) > 2:\n",
    "                    tokens.append(token.lemma_.lower())\n",
    "            if len(tokens) > 0:\n",
    "                clean_sents.append(\" \".join(tokens)) \n",
    "        clean_data.append(clean_sents)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "happy-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mini = clean(train_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(clean_mini[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "strategic-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_voc(data, max_size = 10000):\n",
    "    vocab = defaultdict(int)\n",
    "    vocab[\"<pad>\"] = 0\n",
    "    all_words = list()\n",
    "    word_id = 1\n",
    "    for rev in data:\n",
    "        for word in \" \".join(rev).split(\" \"):\n",
    "            all_words.append(word)\n",
    "    freq = Counter(all_words)\n",
    "    words = freq.most_common(max_size - len(vocab))\n",
    "    word_id = 1\n",
    "    for word,freq in words:\n",
    "        vocab[word] += word_id\n",
    "        word_id += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wound-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<pad>': 0,\n",
       "             'movie': 1,\n",
       "             'film': 2,\n",
       "             'like': 3,\n",
       "             'watch': 4,\n",
       "             'time': 5,\n",
       "             'story': 6,\n",
       "             'think': 7,\n",
       "             'see': 8,\n",
       "             'character': 9,\n",
       "             'good': 10,\n",
       "             'know': 11,\n",
       "             'great': 12,\n",
       "             'well': 13,\n",
       "             'bad': 14,\n",
       "             'scene': 15,\n",
       "             'people': 16,\n",
       "             'play': 17,\n",
       "             'look': 18,\n",
       "             'way': 19,\n",
       "             'love': 20,\n",
       "             'plot': 21,\n",
       "             'get': 22,\n",
       "             'act': 23,\n",
       "             'find': 24,\n",
       "             'go': 25,\n",
       "             'come': 26,\n",
       "             'man': 27,\n",
       "             'end': 28,\n",
       "             'work': 29,\n",
       "             'thing': 30,\n",
       "             'make': 31,\n",
       "             'little': 32,\n",
       "             'actor': 33,\n",
       "             'life': 34,\n",
       "             'try': 35,\n",
       "             'want': 36,\n",
       "             'year': 37,\n",
       "             'feel': 38,\n",
       "             'wrong': 39,\n",
       "             'take': 40,\n",
       "             'give': 41,\n",
       "             'old': 42,\n",
       "             'funny': 43,\n",
       "             'new': 44,\n",
       "             'performance': 45,\n",
       "             'young': 46,\n",
       "             'star': 47,\n",
       "             'real': 48,\n",
       "             'director': 49,\n",
       "             'big': 50,\n",
       "             'world': 51,\n",
       "             'interest': 52,\n",
       "             'comedy': 53,\n",
       "             'woman': 54,\n",
       "             'day': 55,\n",
       "             'actually': 56,\n",
       "             'turn': 57,\n",
       "             'role': 58,\n",
       "             'set': 59,\n",
       "             'lot': 60,\n",
       "             'leave': 61,\n",
       "             'long': 62,\n",
       "             'show': 63,\n",
       "             'begin': 64,\n",
       "             'cast': 65,\n",
       "             'action': 66,\n",
       "             'pretty': 67,\n",
       "             'tell': 68,\n",
       "             'guy': 69,\n",
       "             'write': 70,\n",
       "             'hard': 71,\n",
       "             'laugh': 72,\n",
       "             'girl': 73,\n",
       "             'horror': 74,\n",
       "             'start': 75,\n",
       "             'point': 76,\n",
       "             'kill': 77,\n",
       "             'family': 78,\n",
       "             'book': 79,\n",
       "             'minute': 80,\n",
       "             'read': 81,\n",
       "             'friend': 82,\n",
       "             'live': 83,\n",
       "             'effect': 84,\n",
       "             'enjoy': 85,\n",
       "             'need': 86,\n",
       "             'war': 87,\n",
       "             'fan': 88,\n",
       "             'shoot': 89,\n",
       "             'say': 90,\n",
       "             'original': 91,\n",
       "             'kid': 92,\n",
       "             'series': 93,\n",
       "             'late': 94,\n",
       "             'fact': 95,\n",
       "             'bring': 96,\n",
       "             'screen': 97,\n",
       "             'happen': 98,\n",
       "             'right': 99,\n",
       "             'believe': 100,\n",
       "             'lead': 101,\n",
       "             'reason': 102,\n",
       "             'expect': 103,\n",
       "             'script': 104,\n",
       "             'episode': 105,\n",
       "             'help': 106,\n",
       "             'far': 107,\n",
       "             'idea': 108,\n",
       "             'away': 109,\n",
       "             'music': 110,\n",
       "             'different': 111,\n",
       "             'change': 112,\n",
       "             'line': 113,\n",
       "             'short': 114,\n",
       "             'excellent': 115,\n",
       "             'special': 116,\n",
       "             'murder': 117,\n",
       "             'mean': 118,\n",
       "             'probably': 119,\n",
       "             'place': 120,\n",
       "             'true': 121,\n",
       "             'meet': 122,\n",
       "             'attempt': 123,\n",
       "             'house': 124,\n",
       "             'night': 125,\n",
       "             'fall': 126,\n",
       "             'kind': 127,\n",
       "             'sense': 128,\n",
       "             'decide': 129,\n",
       "             'nice': 130,\n",
       "             'game': 131,\n",
       "             'audience': 132,\n",
       "             'word': 133,\n",
       "             'use': 134,\n",
       "             'bore': 135,\n",
       "             'remember': 136,\n",
       "             'surprise': 137,\n",
       "             'american': 138,\n",
       "             'view': 139,\n",
       "             'beautiful': 140,\n",
       "             'run': 141,\n",
       "             'hear': 142,\n",
       "             'bite': 143,\n",
       "             'title': 144,\n",
       "             'face': 145,\n",
       "             'worth': 146,\n",
       "             'child': 147,\n",
       "             'town': 148,\n",
       "             'version': 149,\n",
       "             'mind': 150,\n",
       "             'john': 151,\n",
       "             'moment': 152,\n",
       "             'review': 153,\n",
       "             'human': 154,\n",
       "             'sure': 155,\n",
       "             'let': 156,\n",
       "             'awful': 157,\n",
       "             'father': 158,\n",
       "             'high': 159,\n",
       "             'have': 160,\n",
       "             'black': 161,\n",
       "             'especially': 162,\n",
       "             'miss': 163,\n",
       "             'stupid': 164,\n",
       "             'home': 165,\n",
       "             'early': 166,\n",
       "             'picture': 167,\n",
       "             'hour': 168,\n",
       "             'main': 169,\n",
       "             'hope': 170,\n",
       "             'boy': 171,\n",
       "             'create': 172,\n",
       "             'small': 173,\n",
       "             'piece': 174,\n",
       "             'hand': 175,\n",
       "             'base': 176,\n",
       "             'school': 177,\n",
       "             'stop': 178,\n",
       "             'absolutely': 179,\n",
       "             'poor': 180,\n",
       "             'age': 181,\n",
       "             'half': 182,\n",
       "             'completely': 183,\n",
       "             'course': 184,\n",
       "             'direct': 185,\n",
       "             'problem': 186,\n",
       "             'dvd': 187,\n",
       "             'open': 188,\n",
       "             'understand': 189,\n",
       "             'call': 190,\n",
       "             'instead': 191,\n",
       "             'fun': 192,\n",
       "             'follow': 193,\n",
       "             'maybe': 194,\n",
       "             'simply': 195,\n",
       "             'couple': 196,\n",
       "             'viewer': 197,\n",
       "             'rate': 198,\n",
       "             'classic': 199,\n",
       "             'totally': 200,\n",
       "             'hollywood': 201,\n",
       "             'sound': 202,\n",
       "             'production': 203,\n",
       "             'sit': 204,\n",
       "             'white': 205,\n",
       "             'entertain': 206,\n",
       "             'lose': 207,\n",
       "             'feature': 208,\n",
       "             'money': 209,\n",
       "             'eye': 210,\n",
       "             'buy': 211,\n",
       "             'sort': 212,\n",
       "             'death': 213,\n",
       "             'amaze': 214,\n",
       "             'close': 215,\n",
       "             'hit': 216,\n",
       "             'mention': 217,\n",
       "             'wonderful': 218,\n",
       "             'rest': 219,\n",
       "             'appear': 220,\n",
       "             '2': 221,\n",
       "             'video': 222,\n",
       "             'numb': 223,\n",
       "             'flick': 224,\n",
       "             'move': 225,\n",
       "             'disappoint': 226,\n",
       "             'drama': 227,\n",
       "             'include': 228,\n",
       "             'lack': 229,\n",
       "             'head': 230,\n",
       "             'sex': 231,\n",
       "             'light': 232,\n",
       "             'waste': 233,\n",
       "             'low': 234,\n",
       "             'terrible': 235,\n",
       "             'quality': 236,\n",
       "             'camera': 237,\n",
       "             'perfect': 238,\n",
       "             'truly': 239,\n",
       "             'killer': 240,\n",
       "             'hold': 241,\n",
       "             'god': 242,\n",
       "             'evil': 243,\n",
       "             'case': 244,\n",
       "             'dead': 245,\n",
       "             'mother': 246,\n",
       "             'save': 247,\n",
       "             'writer': 248,\n",
       "             'car': 249,\n",
       "             'city': 250,\n",
       "             'person': 251,\n",
       "             'comment': 252,\n",
       "             'song': 253,\n",
       "             'dark': 254,\n",
       "             'experience': 255,\n",
       "             'body': 256,\n",
       "             'soon': 257,\n",
       "             'budget': 258,\n",
       "             'suppose': 259,\n",
       "             'learn': 260,\n",
       "             'entire': 261,\n",
       "             'involve': 262,\n",
       "             'fine': 263,\n",
       "             'actress': 264,\n",
       "             'job': 265,\n",
       "             'local': 266,\n",
       "             'wife': 267,\n",
       "             'twist': 268,\n",
       "             'add': 269,\n",
       "             'drug': 270,\n",
       "             'extremely': 271,\n",
       "             'style': 272,\n",
       "             'favorite': 273,\n",
       "             'dance': 274,\n",
       "             'etc': 275,\n",
       "             'police': 276,\n",
       "             'son': 277,\n",
       "             'break': 278,\n",
       "             'recommend': 279,\n",
       "             'dialogue': 280,\n",
       "             'joke': 281,\n",
       "             'talk': 282,\n",
       "             'art': 283,\n",
       "             'violence': 284,\n",
       "             'country': 285,\n",
       "             'fail': 286,\n",
       "             'matt': 287,\n",
       "             'guess': 288,\n",
       "             'group': 289,\n",
       "             'win': 290,\n",
       "             'situation': 291,\n",
       "             'today': 292,\n",
       "             'type': 293,\n",
       "             'die': 294,\n",
       "             'speak': 295,\n",
       "             'catch': 296,\n",
       "             'keep': 297,\n",
       "             'release': 298,\n",
       "             'manage': 299,\n",
       "             'theme': 300,\n",
       "             'pace': 301,\n",
       "             'complete': 302,\n",
       "             'brother': 303,\n",
       "             'allow': 304,\n",
       "             'example': 305,\n",
       "             'wait': 306,\n",
       "             'slow': 307,\n",
       "             'romantic': 308,\n",
       "             'portray': 309,\n",
       "             'stand': 310,\n",
       "             'genre': 311,\n",
       "             'middle': 312,\n",
       "             'heart': 313,\n",
       "             'yes': 314,\n",
       "             'ask': 315,\n",
       "             'decent': 316,\n",
       "             'finally': 317,\n",
       "             'grow': 318,\n",
       "             'thriller': 319,\n",
       "             'cause': 320,\n",
       "             'brilliant': 321,\n",
       "             'credit': 322,\n",
       "             'ago': 323,\n",
       "             'sequence': 324,\n",
       "             'usual': 325,\n",
       "             'hate': 326,\n",
       "             'deal': 327,\n",
       "             'robert': 328,\n",
       "             'touch': 329,\n",
       "             'cool': 330,\n",
       "             'event': 331,\n",
       "             'part': 332,\n",
       "             'easy': 333,\n",
       "             'earth': 334,\n",
       "             'gore': 335,\n",
       "             'obviously': 336,\n",
       "             'crime': 337,\n",
       "             'pay': 338,\n",
       "             'parent': 339,\n",
       "             'huge': 340,\n",
       "             'hell': 341,\n",
       "             'actual': 342,\n",
       "             'apparently': 343,\n",
       "             'strong': 344,\n",
       "             'particular': 345,\n",
       "             'able': 346,\n",
       "             'cop': 347,\n",
       "             'certainly': 348,\n",
       "             'reality': 349,\n",
       "             'figure': 350,\n",
       "             'fire': 351,\n",
       "             'lie': 352,\n",
       "             'theater': 353,\n",
       "             'realize': 354,\n",
       "             'fight': 355,\n",
       "             'offer': 356,\n",
       "             'happy': 357,\n",
       "             'care': 358,\n",
       "             'ridiculous': 359,\n",
       "             'cinema': 360,\n",
       "             'sequel': 361,\n",
       "             'confuse': 362,\n",
       "             'highly': 363,\n",
       "             'television': 364,\n",
       "             'self': 365,\n",
       "             'novel': 366,\n",
       "             'important': 367,\n",
       "             'humor': 368,\n",
       "             'animation': 369,\n",
       "             'voice': 370,\n",
       "             'basically': 371,\n",
       "             'zombie': 372,\n",
       "             'despite': 373,\n",
       "             'usually': 374,\n",
       "             'island': 375,\n",
       "             'name': 376,\n",
       "             'relationship': 377,\n",
       "             'direction': 378,\n",
       "             'message': 379,\n",
       "             'seriously': 380,\n",
       "             'premise': 381,\n",
       "             'documentary': 382,\n",
       "             'brain': 383,\n",
       "             'definitely': 384,\n",
       "             'hot': 385,\n",
       "             'present': 386,\n",
       "             'forget': 387,\n",
       "             'throw': 388,\n",
       "             'level': 389,\n",
       "             'opinion': 390,\n",
       "             'pick': 391,\n",
       "             'mystery': 392,\n",
       "             'suck': 393,\n",
       "             'send': 394,\n",
       "             'box': 395,\n",
       "             'remain': 396,\n",
       "             'hero': 397,\n",
       "             'chance': 398,\n",
       "             'unfortunately': 399,\n",
       "             'weird': 400,\n",
       "             'law': 401,\n",
       "             'describe': 402,\n",
       "             'wonder': 403,\n",
       "             'david': 404,\n",
       "             'consider': 405,\n",
       "             'cut': 406,\n",
       "             'support': 407,\n",
       "             'british': 408,\n",
       "             'jack': 409,\n",
       "             'class': 410,\n",
       "             'dialog': 411,\n",
       "             'power': 412,\n",
       "             'scary': 413,\n",
       "             'eat': 414,\n",
       "             'near': 415,\n",
       "             'deliver': 416,\n",
       "             'past': 417,\n",
       "             'james': 418,\n",
       "             'compare': 419,\n",
       "             'animal': 420,\n",
       "             'nearly': 421,\n",
       "             'screenplay': 422,\n",
       "             'simple': 423,\n",
       "             'force': 424,\n",
       "             'stay': 425,\n",
       "             'shock': 426,\n",
       "             'particularly': 427,\n",
       "             'struggle': 428,\n",
       "             'convince': 429,\n",
       "             'disney': 430,\n",
       "             'history': 431,\n",
       "             'attention': 432,\n",
       "             'michael': 433,\n",
       "             'spend': 434,\n",
       "             'forward': 435,\n",
       "             'predictable': 436,\n",
       "             'return': 437,\n",
       "             'soldier': 438,\n",
       "             'fear': 439,\n",
       "             'obvious': 440,\n",
       "             'space': 441,\n",
       "             'deserve': 442,\n",
       "             'explain': 443,\n",
       "             'clear': 444,\n",
       "             'rock': 445,\n",
       "             'team': 446,\n",
       "             'detail': 447,\n",
       "             'talent': 448,\n",
       "             'street': 449,\n",
       "             'choose': 450,\n",
       "             'fantastic': 451,\n",
       "             'dream': 452,\n",
       "             'business': 453,\n",
       "             'truth': 454,\n",
       "             'walk': 455,\n",
       "             'romance': 456,\n",
       "             'note': 457,\n",
       "             'one': 458,\n",
       "             'element': 459,\n",
       "             'silly': 460,\n",
       "             'possible': 461,\n",
       "             'member': 462,\n",
       "             'channel': 463,\n",
       "             'exactly': 464,\n",
       "             'edit': 465,\n",
       "             'similar': 466,\n",
       "             'intrigue': 467,\n",
       "             'major': 468,\n",
       "             'horrible': 469,\n",
       "             'final': 470,\n",
       "             'talented': 471,\n",
       "             'typical': 472,\n",
       "             'somewhat': 473,\n",
       "             'build': 474,\n",
       "             'cover': 475,\n",
       "             'remind': 476,\n",
       "             'musical': 477,\n",
       "             'french': 478,\n",
       "             'train': 479,\n",
       "             'producer': 480,\n",
       "             'student': 481,\n",
       "             'deep': 482,\n",
       "             'score': 483,\n",
       "             'fill': 484,\n",
       "             'location': 485,\n",
       "             'general': 486,\n",
       "             'lady': 487,\n",
       "             'pull': 488,\n",
       "             'career': 489,\n",
       "             'believable': 490,\n",
       "             'thank': 491,\n",
       "             'doubt': 492,\n",
       "             'continue': 493,\n",
       "             'cheap': 494,\n",
       "             'tire': 495,\n",
       "             'daughter': 496,\n",
       "             'cry': 497,\n",
       "             'draw': 498,\n",
       "             'future': 499,\n",
       "             'door': 500,\n",
       "             'list': 501,\n",
       "             'strange': 502,\n",
       "             'blood': 503,\n",
       "             'hide': 504,\n",
       "             'personal': 505,\n",
       "             'imdb': 506,\n",
       "             'reveal': 507,\n",
       "             'discover': 508,\n",
       "             'marry': 509,\n",
       "             'result': 510,\n",
       "             'sorry': 511,\n",
       "             'bunch': 512,\n",
       "             'accent': 513,\n",
       "             'difference': 514,\n",
       "             'question': 515,\n",
       "             'realistic': 516,\n",
       "             'check': 517,\n",
       "             'overall': 518,\n",
       "             'wish': 519,\n",
       "             'adult': 520,\n",
       "             'success': 521,\n",
       "             'date': 522,\n",
       "             'soundtrack': 523,\n",
       "             'lame': 524,\n",
       "             'notice': 525,\n",
       "             'project': 526,\n",
       "             'pass': 527,\n",
       "             'female': 528,\n",
       "             'dull': 529,\n",
       "             'hilarious': 530,\n",
       "             'america': 531,\n",
       "             'suspense': 532,\n",
       "             'century': 533,\n",
       "             'motion': 534,\n",
       "             'provide': 535,\n",
       "             'produce': 536,\n",
       "             'william': 537,\n",
       "             'gun': 538,\n",
       "             'stuff': 539,\n",
       "             'tom': 540,\n",
       "             'king': 541,\n",
       "             'crap': 542,\n",
       "             'weak': 543,\n",
       "             'english': 544,\n",
       "             'awesome': 545,\n",
       "             'ben': 546,\n",
       "             'form': 547,\n",
       "             'order': 548,\n",
       "             'quickly': 549,\n",
       "             'ice': 550,\n",
       "             'focus': 551,\n",
       "             'fashion': 552,\n",
       "             'water': 553,\n",
       "             'plus': 554,\n",
       "             'effort': 555,\n",
       "             'famous': 556,\n",
       "             'carry': 557,\n",
       "             'judge': 558,\n",
       "             'value': 559,\n",
       "             'wear': 560,\n",
       "             'cliché': 561,\n",
       "             'atmosphere': 562,\n",
       "             'single': 563,\n",
       "             'enjoyable': 564,\n",
       "             'mary': 565,\n",
       "             'pure': 566,\n",
       "             'office': 567,\n",
       "             'contain': 568,\n",
       "             'room': 569,\n",
       "             'spoiler': 570,\n",
       "             'possibly': 571,\n",
       "             'plain': 572,\n",
       "             'mario': 573,\n",
       "             'reach': 574,\n",
       "             'studio': 575,\n",
       "             'crow': 576,\n",
       "             'chase': 577,\n",
       "             'comic': 578,\n",
       "             'dog': 579,\n",
       "             'suspect': 580,\n",
       "             'tear': 581,\n",
       "             'week': 582,\n",
       "             'certain': 583,\n",
       "             'capture': 584,\n",
       "             'ghost': 585,\n",
       "             'company': 586,\n",
       "             'drink': 587,\n",
       "             'suffer': 588,\n",
       "             'non': 589,\n",
       "             'trouble': 590,\n",
       "             'fast': 591,\n",
       "             'surprisingly': 592,\n",
       "             'suggest': 593,\n",
       "             'okay': 594,\n",
       "             'oscar': 595,\n",
       "             'doctor': 596,\n",
       "             'drive': 597,\n",
       "             'charm': 598,\n",
       "             'standard': 599,\n",
       "             'jim': 600,\n",
       "             'visual': 601,\n",
       "             'immediately': 602,\n",
       "             'genius': 603,\n",
       "             'finish': 604,\n",
       "             'rent': 605,\n",
       "             'rip': 606,\n",
       "             'rend': 607,\n",
       "             'smith': 608,\n",
       "             'basic': 609,\n",
       "             'escape': 610,\n",
       "             'serial': 611,\n",
       "             'ruin': 612,\n",
       "             'previous': 613,\n",
       "             'paul': 614,\n",
       "             'adventure': 615,\n",
       "             'imagine': 616,\n",
       "             'bit': 617,\n",
       "             'remake': 618,\n",
       "             'steal': 619,\n",
       "             'fake': 620,\n",
       "             'battle': 621,\n",
       "             'beat': 622,\n",
       "             'successful': 623,\n",
       "             'edge': 624,\n",
       "             'season': 625,\n",
       "             'husband': 626,\n",
       "             'memorable': 627,\n",
       "             'cinematography': 628,\n",
       "             'army': 629,\n",
       "             'grade': 630,\n",
       "             'sleep': 631,\n",
       "             'clearly': 632,\n",
       "             'stage': 633,\n",
       "             'creature': 634,\n",
       "             'slightly': 635,\n",
       "             'hole': 636,\n",
       "             'manner': 637,\n",
       "             'travel': 638,\n",
       "             'blue': 639,\n",
       "             'incredible': 640,\n",
       "             'society': 641,\n",
       "             'batman': 642,\n",
       "             'search': 643,\n",
       "             'admit': 644,\n",
       "             'intelligent': 645,\n",
       "             'superb': 646,\n",
       "             'air': 647,\n",
       "             'average': 648,\n",
       "             'fit': 649,\n",
       "             'storyline': 650,\n",
       "             'planet': 651,\n",
       "             'george': 652,\n",
       "             'development': 653,\n",
       "             'sister': 654,\n",
       "             'depth': 655,\n",
       "             'terrific': 656,\n",
       "             'smart': 657,\n",
       "             'mouth': 658,\n",
       "             'limit': 659,\n",
       "             'approach': 660,\n",
       "             'protagonist': 661,\n",
       "             'ready': 662,\n",
       "             'drag': 663,\n",
       "             'prove': 664,\n",
       "             'mix': 665,\n",
       "             'public': 666,\n",
       "             'solid': 667,\n",
       "             'handle': 668,\n",
       "             'western': 669,\n",
       "             'narrative': 670,\n",
       "             'modern': 671,\n",
       "             'treat': 672,\n",
       "             'crazy': 673,\n",
       "             'arrive': 674,\n",
       "             'plan': 675,\n",
       "             'nature': 676,\n",
       "             'impression': 677,\n",
       "             'fairly': 678,\n",
       "             'listen': 679,\n",
       "             'claim': 680,\n",
       "             'government': 681,\n",
       "             'badly': 682,\n",
       "             'agree': 683,\n",
       "             'paint': 684,\n",
       "             'gay': 685,\n",
       "             'criminal': 686,\n",
       "             'mess': 687,\n",
       "             'vampire': 688,\n",
       "             'state': 689,\n",
       "             'italian': 690,\n",
       "             'sexy': 691,\n",
       "             'stun': 692,\n",
       "             'host': 693,\n",
       "             'alien': 694,\n",
       "             'attack': 695,\n",
       "             'concept': 696,\n",
       "             'masterpiece': 697,\n",
       "             'political': 698,\n",
       "             'root': 699,\n",
       "             'annoy': 700,\n",
       "             'hardly': 701,\n",
       "             'language': 702,\n",
       "             'familiar': 703,\n",
       "             'german': 704,\n",
       "             'entertainment': 705,\n",
       "             'outside': 706,\n",
       "             'putt': 707,\n",
       "             'stone': 708,\n",
       "             'zero': 709,\n",
       "             'critic': 710,\n",
       "             'creepy': 711,\n",
       "             'land': 712,\n",
       "             'copy': 713,\n",
       "             'victim': 714,\n",
       "             'animate': 715,\n",
       "             'depict': 716,\n",
       "             'scare': 717,\n",
       "             'fantasy': 718,\n",
       "             'park': 719,\n",
       "             'sci': 720,\n",
       "             'perform': 721,\n",
       "             'likable': 722,\n",
       "             'image': 723,\n",
       "             'suddenly': 724,\n",
       "             'monster': 725,\n",
       "             'bizarre': 726,\n",
       "             'emotional': 727,\n",
       "             'nominate': 728,\n",
       "             'aspect': 729,\n",
       "             'bear': 730,\n",
       "             'dumb': 731,\n",
       "             'numerous': 732,\n",
       "             'poorly': 733,\n",
       "             'literally': 734,\n",
       "             'center': 735,\n",
       "             'disgust': 736,\n",
       "             'ryan': 737,\n",
       "             'detective': 738,\n",
       "             'steve': 739,\n",
       "             'male': 740,\n",
       "             'cult': 741,\n",
       "             'baby': 742,\n",
       "             'count': 743,\n",
       "             'accept': 744,\n",
       "             'computer': 745,\n",
       "             'clue': 746,\n",
       "             'impossible': 747,\n",
       "             'hospital': 748,\n",
       "             'difficult': 749,\n",
       "             'require': 750,\n",
       "             'mark': 751,\n",
       "             'extra': 752,\n",
       "             'subject': 753,\n",
       "             'gem': 754,\n",
       "             'robin': 755,\n",
       "             'bond': 756,\n",
       "             'japanese': 757,\n",
       "             'display': 758,\n",
       "             'journey': 759,\n",
       "             'sell': 760,\n",
       "             'bill': 761,\n",
       "             'villain': 762,\n",
       "             'folk': 763,\n",
       "             'richard': 764,\n",
       "             'emotion': 765,\n",
       "             'rare': 766,\n",
       "             'religion': 767,\n",
       "             'girlfriend': 768,\n",
       "             'clever': 769,\n",
       "             'track': 770,\n",
       "             'social': 771,\n",
       "             'portrayal': 772,\n",
       "             'party': 773,\n",
       "             'pathetic': 774,\n",
       "             'loud': 775,\n",
       "             'lost': 776,\n",
       "             'santa': 777,\n",
       "             'regard': 778,\n",
       "             'reference': 779,\n",
       "             'impress': 780,\n",
       "             'ignore': 781,\n",
       "             'york': 782,\n",
       "             'dress': 783,\n",
       "             'vote': 784,\n",
       "             'fresh': 785,\n",
       "             'band': 786,\n",
       "             'mistake': 787,\n",
       "             'nasty': 788,\n",
       "             'eventually': 789,\n",
       "             'appeal': 790,\n",
       "             'secret': 791,\n",
       "             'lesson': 792,\n",
       "             'mile': 793,\n",
       "             'perfectly': 794,\n",
       "             'thin': 795,\n",
       "             'complex': 796,\n",
       "             'aside': 797,\n",
       "             'large': 798,\n",
       "             'cold': 799,\n",
       "             'quick': 800,\n",
       "             'sad': 801,\n",
       "             'engage': 802,\n",
       "             'stretch': 803,\n",
       "             'indian': 804,\n",
       "             'tension': 805,\n",
       "             'skeleton': 806,\n",
       "             'program': 807,\n",
       "             'wood': 808,\n",
       "             'issue': 809,\n",
       "             'unique': 810,\n",
       "             'lover': 811,\n",
       "             'kick': 812,\n",
       "             'mad': 813,\n",
       "             'fair': 814,\n",
       "             'graphic': 815,\n",
       "             'silent': 816,\n",
       "             'rich': 817,\n",
       "             'free': 818,\n",
       "             'enter': 819,\n",
       "             'relate': 820,\n",
       "             'develope': 821,\n",
       "             'college': 822,\n",
       "             'station': 823,\n",
       "             'sport': 824,\n",
       "             'photograph': 825,\n",
       "             'charlie': 826,\n",
       "             'disturb': 827,\n",
       "             'costume': 828,\n",
       "             'bother': 829,\n",
       "             'seat': 830,\n",
       "             'rule': 831,\n",
       "             'footage': 832,\n",
       "             'blow': 833,\n",
       "             'sexual': 834,\n",
       "             'photography': 835,\n",
       "             'best': 836,\n",
       "             'steven': 837,\n",
       "             'joseph': 838,\n",
       "             'store': 839,\n",
       "             'round': 840,\n",
       "             'month': 841,\n",
       "             'adaptation': 842,\n",
       "             'passion': 843,\n",
       "             'sub': 844,\n",
       "             'homeless': 845,\n",
       "             'spoil': 846,\n",
       "             'total': 847,\n",
       "             'stick': 848,\n",
       "             'laurel': 849,\n",
       "             'christmas': 850,\n",
       "             'succeed': 851,\n",
       "             'reviewer': 852,\n",
       "             'mainly': 853,\n",
       "             'prison': 854,\n",
       "             'match': 855,\n",
       "             'allen': 856,\n",
       "             'shot': 857,\n",
       "             'encounter': 858,\n",
       "             'sea': 859,\n",
       "             'humour': 860,\n",
       "             'warn': 861,\n",
       "             'roll': 862,\n",
       "             'terror': 863,\n",
       "             'destroy': 864,\n",
       "             'appearance': 865,\n",
       "             'club': 866,\n",
       "             'cash': 867,\n",
       "             'trip': 868,\n",
       "             'challenge': 869,\n",
       "             'target': 870,\n",
       "             'era': 871,\n",
       "             'sam': 872,\n",
       "             'haunt': 873,\n",
       "             'unlike': 874,\n",
       "             'officer': 875,\n",
       "             'excite': 876,\n",
       "             'insult': 877,\n",
       "             'utterly': 878,\n",
       "             'cute': 879,\n",
       "             'worthy': 880,\n",
       "             'singe': 881,\n",
       "             'represent': 882,\n",
       "             'rise': 883,\n",
       "             'report': 884,\n",
       "             'board': 885,\n",
       "             'fly': 886,\n",
       "             'model': 887,\n",
       "             'comedic': 888,\n",
       "             'flat': 889,\n",
       "             'term': 890,\n",
       "             'easily': 891,\n",
       "             'subtle': 892,\n",
       "             'chick': 893,\n",
       "             'record': 894,\n",
       "             'ship': 895,\n",
       "             'violent': 896,\n",
       "             'cartoon': 897,\n",
       "             'van': 898,\n",
       "             'festival': 899,\n",
       "             'jane': 900,\n",
       "             'hurt': 901,\n",
       "             'outstanding': 902,\n",
       "             'ability': 903,\n",
       "             'tie': 904,\n",
       "             'cat': 905,\n",
       "             'garbage': 906,\n",
       "             'up': 907,\n",
       "             'road': 908,\n",
       "             'teach': 909,\n",
       "             'queen': 910,\n",
       "             'thoroughly': 911,\n",
       "             'community': 912,\n",
       "             'step': 913,\n",
       "             'werewolf': 914,\n",
       "             'gag': 915,\n",
       "             'fat': 916,\n",
       "             'slowly': 917,\n",
       "             'pilot': 918,\n",
       "             'maker': 919,\n",
       "             'avoid': 920,\n",
       "             'witty': 921,\n",
       "             'decade': 922,\n",
       "             'drop': 923,\n",
       "             'positive': 924,\n",
       "             'cheesy': 925,\n",
       "             'stereotype': 926,\n",
       "             'golden': 927,\n",
       "             'straight': 928,\n",
       "             'receive': 929,\n",
       "             'karen': 930,\n",
       "             'conflict': 931,\n",
       "             'period': 932,\n",
       "             'north': 933,\n",
       "             'introduce': 934,\n",
       "             'bank': 935,\n",
       "             'assume': 936,\n",
       "             'ride': 937,\n",
       "             'race': 938,\n",
       "             'surround': 939,\n",
       "             'thousand': 940,\n",
       "             'leader': 941,\n",
       "             'morning': 942,\n",
       "             'porn': 943,\n",
       "             'identity': 944,\n",
       "             'commit': 945,\n",
       "             'lovely': 946,\n",
       "             'monkey': 947,\n",
       "             'flaw': 948,\n",
       "             'expectation': 949,\n",
       "             'smile': 950,\n",
       "             'mysterious': 951,\n",
       "             'mood': 952,\n",
       "             'sadly': 953,\n",
       "             'red': 954,\n",
       "             'witch': 955,\n",
       "             'ugly': 956,\n",
       "             'wind': 957,\n",
       "             'tale': 958,\n",
       "             'wall': 959,\n",
       "             'color': 960,\n",
       "             'scream': 961,\n",
       "             'kevin': 962,\n",
       "             'rain': 963,\n",
       "             'material': 964,\n",
       "             'witness': 965,\n",
       "             'military': 966,\n",
       "             'recent': 967,\n",
       "             'ahead': 968,\n",
       "             'apart': 969,\n",
       "             'design': 970,\n",
       "             'scott': 971,\n",
       "             'metal': 972,\n",
       "             'loose': 973,\n",
       "             'dare': 974,\n",
       "             'spirit': 975,\n",
       "             'relation': 976,\n",
       "             'sacrifice': 977,\n",
       "             'hunt': 978,\n",
       "             'replace': 979,\n",
       "             'respect': 980,\n",
       "             'odd': 981,\n",
       "             'formula': 982,\n",
       "             'boll': 983,\n",
       "             'appreciate': 984,\n",
       "             'exception': 985,\n",
       "             'shame': 986,\n",
       "             'plenty': 987,\n",
       "             'pack': 988,\n",
       "             'amuse': 989,\n",
       "             'blockbuster': 990,\n",
       "             'concern': 991,\n",
       "             'civil': 992,\n",
       "             'entirely': 993,\n",
       "             'angry': 994,\n",
       "             'render': 995,\n",
       "             'ultimately': 996,\n",
       "             'promise': 997,\n",
       "             'originally': 998,\n",
       "             'honestly': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_mini = make_voc(clean_mini)\n",
    "vocab_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "wicked-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, vocab):\n",
    "    idxs = [vocab[w] if w in vocab else 0 for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "violent-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(data):\n",
    "    train = list()\n",
    "    for rev in data:\n",
    "        sents = list()\n",
    "        for sent in rev:\n",
    "            sents.append(prepare_sequence(sent.split(\" \"), vocab_mini))\n",
    "        train.append(sents)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "conservative-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mini = prep_train(clean_mini)\n",
    "sent_mini = np.array(df[\"sentiment\"][:25000], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "inappropriate-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_vectorizer(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=512, hidden_dim=256, vocab_size=10000):\n",
    "        super(lstm_vectorizer, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = 2, bidirectional = True)\n",
    "\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        \n",
    "        embeds = embeds.to(\"cuda\")\n",
    "\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        \n",
    "        lstm_out = lstm_out.to(\"cuda\")\n",
    "        \n",
    "        #hidden = self.hidden(lstm_out)\n",
    "        return torch.mean(lstm_out.squeeze(1), axis=0) # torch.mean(hidden, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "leading-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module): \n",
    "    def __init__(self, embdim = 512, hidden_unit = 100, output_dim = 2):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(10 * embdim, hidden_unit)\n",
    "        self.output = nn.Linear(hidden_unit, output_dim)\n",
    "\n",
    "    def forward(self, features):\n",
    "        hn = self.hidden(features)\n",
    "        out = self.output(hn)\n",
    "        \n",
    "        return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "owned-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = lstm_vectorizer()\n",
    "        self.mlp = MLP()\n",
    "\n",
    "    def forward(self, review):\n",
    "        #need 10 outputs concat\n",
    "        lstm_vector = [self.lstm.forward(sent.to(\"cuda\")) for sent in review]\n",
    "        lstm_vector.extend([torch.FloatTensor(512 *[0]).to(\"cuda\")] * (10 - len(lstm_vector))) # padding\n",
    "        lstm_vector = lstm_vector\n",
    "        input_mlp = torch.cat(lstm_vector).to(\"cuda\")\n",
    "        input_mlp = input_mlp.to(\"cuda\")\n",
    "        output_mlp = self.mlp.forward(input_mlp)\n",
    "        output_mlp = output_mlp.to(\"cuda\")\n",
    "        return output_mlp\n",
    "\n",
    "net = net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "short-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, revs, sents):\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    for epoch in range(1):\n",
    "        p = 0\n",
    "        for i, rev in enumerate(revs[:10000]):\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            \n",
    "            target = torch.tensor([sents[i]])\n",
    "            target = target.to(\"cuda\")\n",
    "\n",
    "            # Step 3. Run our forward pass.\n",
    "            forward = model(rev)\n",
    "            forward = forward.to(\"cuda\")\n",
    "            \n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            loss = loss_function(m(forward.unsqueeze(0)), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                p+=1\n",
    "                print(\"loss:\", loss.item())\n",
    "                print(p,\"% ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "liberal-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6474443078041077\n",
      "1 % ...\n",
      "loss: 0.7139332890510559\n",
      "2 % ...\n",
      "loss: 0.7376116514205933\n",
      "3 % ...\n",
      "loss: 0.5228411555290222\n",
      "4 % ...\n",
      "loss: 0.46148085594177246\n",
      "5 % ...\n",
      "loss: 0.5821271538734436\n",
      "6 % ...\n",
      "loss: 0.41785117983818054\n",
      "7 % ...\n",
      "loss: 0.527249813079834\n",
      "8 % ...\n",
      "loss: 0.9399275779724121\n",
      "9 % ...\n",
      "loss: 0.2312680035829544\n",
      "10 % ...\n",
      "loss: 0.0010920758359134197\n",
      "11 % ...\n",
      "loss: 0.03275252878665924\n",
      "12 % ...\n",
      "loss: 0.0003332536434754729\n",
      "13 % ...\n",
      "loss: 0.24712321162223816\n",
      "14 % ...\n",
      "loss: 0.4940148591995239\n",
      "15 % ...\n",
      "loss: 0.000556314189452678\n",
      "16 % ...\n",
      "loss: 1.0487689971923828\n",
      "17 % ...\n",
      "loss: 2.111652374267578\n",
      "18 % ...\n",
      "loss: 0.12464223057031631\n",
      "19 % ...\n",
      "loss: 0.15036459267139435\n",
      "20 % ...\n",
      "loss: 0.3545103669166565\n",
      "21 % ...\n",
      "loss: 0.2978688180446625\n",
      "22 % ...\n",
      "loss: 0.34357285499572754\n",
      "23 % ...\n",
      "loss: 0.0008294717408716679\n",
      "24 % ...\n",
      "loss: 0.17332836985588074\n",
      "25 % ...\n",
      "loss: 0.010815335437655449\n",
      "26 % ...\n",
      "loss: 0.7060902714729309\n",
      "27 % ...\n",
      "loss: 0.6943464875221252\n",
      "28 % ...\n",
      "loss: 0.3503696024417877\n",
      "29 % ...\n",
      "loss: 0.504270076751709\n",
      "30 % ...\n",
      "loss: 0.028148911893367767\n",
      "31 % ...\n",
      "loss: 0.10565149039030075\n",
      "32 % ...\n",
      "loss: 0.21076524257659912\n",
      "33 % ...\n",
      "loss: 0.1531200408935547\n",
      "34 % ...\n",
      "loss: 0.20895957946777344\n",
      "35 % ...\n",
      "loss: 0.1671004444360733\n",
      "36 % ...\n",
      "loss: 0.10548007488250732\n",
      "37 % ...\n",
      "loss: 0.5502139925956726\n",
      "38 % ...\n",
      "loss: 0.5540051460266113\n",
      "39 % ...\n",
      "loss: 0.9149900674819946\n",
      "40 % ...\n",
      "loss: 0.9843904972076416\n",
      "41 % ...\n",
      "loss: 0.10996879637241364\n",
      "42 % ...\n",
      "loss: 0.4360958933830261\n",
      "43 % ...\n",
      "loss: 0.44818198680877686\n",
      "44 % ...\n",
      "loss: 0.5248206853866577\n",
      "45 % ...\n",
      "loss: 0.01144003588706255\n",
      "46 % ...\n",
      "loss: 0.4247478246688843\n",
      "47 % ...\n",
      "loss: 0.3729018568992615\n",
      "48 % ...\n",
      "loss: 0.08765581250190735\n",
      "49 % ...\n",
      "loss: 0.3172229826450348\n",
      "50 % ...\n",
      "loss: 1.517162799835205\n",
      "51 % ...\n",
      "loss: 0.24592848122119904\n",
      "52 % ...\n",
      "loss: 0.0036954462993890047\n",
      "53 % ...\n",
      "loss: 0.02457069791853428\n",
      "54 % ...\n",
      "loss: 0.13167177140712738\n",
      "55 % ...\n",
      "loss: 0.15965378284454346\n",
      "56 % ...\n",
      "loss: 0.40766605734825134\n",
      "57 % ...\n",
      "loss: 0.11845716089010239\n",
      "58 % ...\n",
      "loss: 0.0675877258181572\n",
      "59 % ...\n",
      "loss: 0.267783522605896\n",
      "60 % ...\n",
      "loss: 0.005664843134582043\n",
      "61 % ...\n",
      "loss: 0.09277563542127609\n",
      "62 % ...\n",
      "loss: 0.13807426393032074\n",
      "63 % ...\n",
      "loss: 0.2675773799419403\n",
      "64 % ...\n",
      "loss: 1.4294931888580322\n",
      "65 % ...\n",
      "loss: 0.005598105024546385\n",
      "66 % ...\n",
      "loss: 0.4694717526435852\n",
      "67 % ...\n",
      "loss: 0.08783882111310959\n",
      "68 % ...\n",
      "loss: 0.23405638337135315\n",
      "69 % ...\n",
      "loss: 0.17222824692726135\n",
      "70 % ...\n",
      "loss: 0.0016208856832236052\n",
      "71 % ...\n",
      "loss: 2.1080033779144287\n",
      "72 % ...\n",
      "loss: 0.6102501749992371\n",
      "73 % ...\n",
      "loss: 0.15537726879119873\n",
      "74 % ...\n",
      "loss: 1.3539485931396484\n",
      "75 % ...\n",
      "loss: 0.10457704961299896\n",
      "76 % ...\n",
      "loss: 0.2821727991104126\n",
      "77 % ...\n",
      "loss: 0.0033635490108281374\n",
      "78 % ...\n",
      "loss: 0.0059204925782978535\n",
      "79 % ...\n",
      "loss: 0.1452309787273407\n",
      "80 % ...\n",
      "loss: 0.0033927755430340767\n",
      "81 % ...\n",
      "loss: 0.35506123304367065\n",
      "82 % ...\n",
      "loss: 1.5308171510696411\n",
      "83 % ...\n",
      "loss: 1.0508524179458618\n",
      "84 % ...\n",
      "loss: 0.21981637179851532\n",
      "85 % ...\n",
      "loss: 0.30618685483932495\n",
      "86 % ...\n",
      "loss: 0.10405411571264267\n",
      "87 % ...\n",
      "loss: 0.19998399913311005\n",
      "88 % ...\n",
      "loss: 0.053906187415122986\n",
      "89 % ...\n",
      "loss: 0.9412257671356201\n",
      "90 % ...\n",
      "loss: 0.12141839414834976\n",
      "91 % ...\n",
      "loss: 0.32438477873802185\n",
      "92 % ...\n",
      "loss: 0.0361906960606575\n",
      "93 % ...\n",
      "loss: 0.16160346567630768\n",
      "94 % ...\n",
      "loss: 1.0395557880401611\n",
      "95 % ...\n",
      "loss: 0.08856616914272308\n",
      "96 % ...\n",
      "loss: 0.015715204179286957\n",
      "97 % ...\n",
      "loss: 0.42054328322410583\n",
      "98 % ...\n",
      "loss: 1.738332748413086\n",
      "99 % ...\n",
      "loss: 1.0213258266448975\n",
      "100 % ...\n"
     ]
    }
   ],
   "source": [
    "net = net.to(\"cuda\")\n",
    "train_net(net, train_mini, sent_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "legendary-stretch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "preds = list()\n",
    "for rev in train_mini[12000:12500]:\n",
    "    with torch.no_grad():\n",
    "        scores = net(rev)\n",
    "        probs = torch.exp(scores)\n",
    "        preds.append(torch.argmax(probs.unsqueeze(0), dim=1)[0].item())\n",
    "\n",
    "golds = sent_mini[12000:12500]\n",
    "golds = golds.astype(int)\n",
    "accuracy_score(golds, preds)\n",
    "cm = confusion_matrix(golds, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "accuracy_score(golds, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "architectural-maine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6976, -0.6888], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out = net.forward(train_mini[0])\n",
    "m = nn.LogSoftmax(dim=0)\n",
    "m(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alone-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY not text\n",
    "for i, row in df.iterrows():\n",
    "    if row[\"sentiment\"] == \"positive\":\n",
    "        df.at[i,'sentiment'] = 1\n",
    "    else:\n",
    "        df.at[i,'sentiment'] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aquatic-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "#some cleaning\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    doc = nlp(row[\"review\"], disable = [\"ner\", \"parser\", \"tagger\"])\n",
    "    rev = list()\n",
    "    for token in doc:\n",
    "        if token.is_alpha and not token.is_stop and len(token.text) > 2:\n",
    "            rev.append(token.lemma_.lower())\n",
    "    df.at[i,\"review\"] = \" \".join(rev)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "rough-dylan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'<pad>': 0, '<bos>': 1, '<eos>': 2, '<unk>': 3})\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "9996\n"
     ]
    }
   ],
   "source": [
    "def make_vocab(df, max_size = 10000):\n",
    "    vocab = defaultdict(int)\n",
    "    vocab[\"<pad>\"] = 0\n",
    "    vocab[\"<bos>\"] = 1\n",
    "    vocab[\"<eos>\"] = 2\n",
    "    vocab[\"<unk>\"] = 3\n",
    "    print(vocab)\n",
    "    # do counter\n",
    "    #get most common\n",
    "    #put in dict. \n",
    "    all_words = list()\n",
    "    word_id = 4\n",
    "    for i, row in df.iterrows():\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        for word in row[\"review\"].split(\" \"):\n",
    "            all_words.append(word)\n",
    "    freq = Counter(all_words)\n",
    "    words = freq.most_common(max_size - len(vocab))\n",
    "    print(len(words))\n",
    "    word_id = 4\n",
    "    for word,freq in words:\n",
    "        vocab[word] += word_id\n",
    "        word_id += 1\n",
    "    return vocab\n",
    "vocab = make_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "boolean-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, vocab):\n",
    "    idxs = [vocab[w] if w in vocab else 0 for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepare_sequence(df.iloc[0][\"review\"].split(\" \"), vocab) \n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-covering",
   "metadata": {},
   "source": [
    "#### prep training data and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "random-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rev = list()\n",
    "word_sents = list()\n",
    "for i, rev in enumerate(df[\"review\"].to_numpy()):\n",
    "    word_sents.append(rev.split(\" \"))\n",
    "    train_rev.append(prepare_sequence(rev.split(\" \"), vocab))\n",
    "train_sent = df[\"sentiment\"].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "useful-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMclassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMclassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = 2, bidirectional = True)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.out = nn.Linear(2 * hidden_dim, 2)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        embeds = embeds.to(\"cuda\")\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        lstm_out = lstm_out.to(\"cuda\")\n",
    "        out = self.out(lstm_out) #lstm_out[-1]\n",
    "        out = out.to(\"cuda\")\n",
    "        return torch.mean(out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "noble-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMclassifier(100,100,len(vocab),4)\n",
    "lstm = lstm.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "technical-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0123,  0.0414]], device='cuda:0')\n",
      "loss: 0.666625440120697\n",
      "1 % ...\n",
      "loss: 1.0152952671051025\n",
      "2 % ...\n",
      "loss: 0.4910854697227478\n",
      "3 % ...\n",
      "loss: 0.738742470741272\n",
      "4 % ...\n",
      "loss: 0.5944241285324097\n",
      "5 % ...\n",
      "loss: 0.5740475654602051\n",
      "6 % ...\n",
      "loss: 0.5242593884468079\n",
      "7 % ...\n",
      "loss: 1.699992299079895\n",
      "8 % ...\n",
      "loss: 0.557603120803833\n",
      "9 % ...\n",
      "loss: 0.30870094895362854\n",
      "10 % ...\n",
      "loss: 0.012244884856045246\n",
      "11 % ...\n",
      "loss: 1.3282191753387451\n",
      "12 % ...\n",
      "loss: 0.0005183068569749594\n",
      "13 % ...\n",
      "loss: 0.020454423502087593\n",
      "14 % ...\n",
      "loss: 0.22770552337169647\n",
      "15 % ...\n",
      "loss: 0.06272442638874054\n",
      "16 % ...\n",
      "loss: 0.3894866406917572\n",
      "17 % ...\n",
      "loss: 0.9748966693878174\n",
      "18 % ...\n",
      "loss: 0.03551144152879715\n",
      "19 % ...\n",
      "loss: 0.13445299863815308\n",
      "20 % ...\n",
      "loss: 0.3654627203941345\n",
      "21 % ...\n",
      "loss: 0.2110596001148224\n",
      "22 % ...\n",
      "loss: 0.7135845422744751\n",
      "23 % ...\n",
      "loss: 0.004338139668107033\n",
      "24 % ...\n",
      "loss: 0.013249566778540611\n",
      "25 % ...\n",
      "loss: 0.059060271829366684\n",
      "26 % ...\n",
      "loss: 0.1750289648771286\n",
      "27 % ...\n",
      "loss: 0.02778804861009121\n",
      "28 % ...\n",
      "loss: 0.25683629512786865\n",
      "29 % ...\n",
      "loss: 0.09860771894454956\n",
      "30 % ...\n",
      "loss: 0.19148561358451843\n",
      "31 % ...\n",
      "loss: 0.053740810602903366\n",
      "32 % ...\n",
      "loss: 0.08964692801237106\n",
      "33 % ...\n",
      "loss: 0.11825022846460342\n",
      "34 % ...\n",
      "loss: 0.28210458159446716\n",
      "35 % ...\n",
      "loss: 0.4475461542606354\n",
      "36 % ...\n",
      "loss: 0.4380989968776703\n",
      "37 % ...\n",
      "loss: 0.025003647431731224\n",
      "38 % ...\n",
      "loss: 0.011543741449713707\n",
      "39 % ...\n",
      "loss: 1.8031173944473267\n",
      "40 % ...\n",
      "loss: 0.870229184627533\n",
      "41 % ...\n",
      "loss: 0.16527241468429565\n",
      "42 % ...\n",
      "loss: 0.5223077535629272\n",
      "43 % ...\n",
      "loss: 0.06816815584897995\n",
      "44 % ...\n",
      "loss: 0.038110267370939255\n",
      "45 % ...\n",
      "loss: 0.03007482923567295\n",
      "46 % ...\n",
      "loss: 0.13117662072181702\n",
      "47 % ...\n",
      "loss: 0.28239545226097107\n",
      "48 % ...\n",
      "loss: 0.013142861425876617\n",
      "49 % ...\n",
      "loss: 0.050876714289188385\n",
      "50 % ...\n",
      "loss: 0.43677160143852234\n",
      "51 % ...\n",
      "loss: 0.011513927020132542\n",
      "52 % ...\n",
      "loss: 0.12753455340862274\n",
      "53 % ...\n",
      "loss: 0.26465463638305664\n",
      "54 % ...\n",
      "loss: 0.009364726021885872\n",
      "55 % ...\n",
      "loss: 0.022708958014845848\n",
      "56 % ...\n",
      "loss: 0.63405442237854\n",
      "57 % ...\n",
      "loss: 0.3635307550430298\n",
      "58 % ...\n",
      "loss: 0.1094554141163826\n",
      "59 % ...\n",
      "loss: 1.0089846849441528\n",
      "60 % ...\n",
      "loss: 0.0032574469223618507\n",
      "61 % ...\n",
      "loss: 0.17085041105747223\n",
      "62 % ...\n",
      "loss: 0.06306226551532745\n",
      "63 % ...\n",
      "loss: 0.7788488864898682\n",
      "64 % ...\n",
      "loss: 1.3775547742843628\n",
      "65 % ...\n",
      "loss: 0.11068929731845856\n",
      "66 % ...\n",
      "loss: 0.8363238573074341\n",
      "67 % ...\n",
      "loss: 0.18702228367328644\n",
      "68 % ...\n",
      "loss: 0.16724063456058502\n",
      "69 % ...\n",
      "loss: 0.21299713850021362\n",
      "70 % ...\n",
      "loss: 0.022216252982616425\n",
      "71 % ...\n",
      "loss: 0.6763267517089844\n",
      "72 % ...\n",
      "loss: 0.27170833945274353\n",
      "73 % ...\n",
      "loss: 0.01603282243013382\n",
      "74 % ...\n",
      "loss: 0.48174452781677246\n",
      "75 % ...\n",
      "loss: 0.07995349913835526\n",
      "76 % ...\n",
      "loss: 0.060765642672777176\n",
      "77 % ...\n",
      "loss: 0.0003408804477658123\n",
      "78 % ...\n",
      "loss: 0.08269809931516647\n",
      "79 % ...\n",
      "loss: 0.035372793674468994\n",
      "80 % ...\n",
      "loss: 0.27686890959739685\n",
      "81 % ...\n",
      "loss: 0.11091423779726028\n",
      "82 % ...\n",
      "loss: 4.263782501220703\n",
      "83 % ...\n",
      "loss: 0.11613022536039352\n",
      "84 % ...\n",
      "loss: 0.43950405716896057\n",
      "85 % ...\n",
      "loss: 0.7394925355911255\n",
      "86 % ...\n",
      "loss: 0.09394606202840805\n",
      "87 % ...\n",
      "loss: 0.08186377584934235\n",
      "88 % ...\n",
      "loss: 0.0013493727892637253\n",
      "89 % ...\n",
      "loss: 0.10205598920583725\n",
      "90 % ...\n",
      "loss: 0.007024473510682583\n",
      "91 % ...\n",
      "loss: 0.33955812454223633\n",
      "92 % ...\n",
      "loss: 0.06464798003435135\n",
      "93 % ...\n",
      "loss: 0.9454777240753174\n",
      "94 % ...\n",
      "loss: 0.5637791752815247\n",
      "95 % ...\n",
      "loss: 0.0804067999124527\n",
      "96 % ...\n",
      "loss: 0.07309243828058243\n",
      "97 % ...\n",
      "loss: 0.10450027883052826\n",
      "98 % ...\n",
      "loss: 3.6179347038269043\n",
      "99 % ...\n",
      "loss: 1.1408191919326782\n",
      "100 % ...\n"
     ]
    }
   ],
   "source": [
    "def train_lstm(model, revs, sents):\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "    # See what the scores are before training\n",
    "    # Note that element i,j of the output is the score for tag j for word i.\n",
    "    # Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        first = revs[0]\n",
    "        first = first.to(\"cuda\")\n",
    "        scores = model(first)\n",
    "        print(scores)\n",
    "    for epoch in range(1):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "        p = 0\n",
    "        for i, rev in enumerate(revs[:10000]):\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "\n",
    "            target = torch.tensor([sents[i]])\n",
    "            target = target.to(\"cuda\")\n",
    "            rev = rev.to(\"cuda\")\n",
    "            # Step 3. Run our forward pass.\n",
    "            predict = model(rev)\n",
    "            \n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            loss = loss_function(m(predict), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                p+=1\n",
    "                print(\"loss:\", loss.item())\n",
    "                print(p,\"% ...\")\n",
    "train_lstm(lstm, train_rev, train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "neither-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "#print(df.iloc[2][\"review\"])\n",
    "preds = list()\n",
    "for rev in train_rev[12000:12500]:\n",
    "    with torch.no_grad():\n",
    "        first = train_rev[2]\n",
    "        rev = rev.to(\"cuda\")\n",
    "        scores = lstm(rev)\n",
    "        probs = torch.exp(m(scores))\n",
    "        #print(probs)\n",
    "        #print(torch.argmax(probs, dim=1))\n",
    "        preds.append(torch.argmax(probs, dim=1)[0].item())\n",
    "        #print(\"gold: \", train_sent[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "medium-cathedral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.822"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "golds = train_sent[12000:12500]\n",
    "preds\n",
    "golds = golds.astype(int)\n",
    "accuracy_score(golds, preds)\n",
    "cm = confusion_matrix(golds, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "accuracy_score(golds, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-eleven",
   "metadata": {},
   "source": [
    "### Baseline model logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow \n",
    "def make_bow_vector(sentence, vocab):\n",
    "    vec = torch.zeros(len(vocab))\n",
    "    for word in sentence:\n",
    "        if word in vocab:\n",
    "            vec[vocab[word]] += 1\n",
    "        else:\n",
    "            vec[0] += 1\n",
    "    return vec.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = make_bow_vector(word_sents[0], vocab)\n",
    "len(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(lr, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels) # do i do a cbow or can i cheat?\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, rev):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        out = self.linear(rev)\n",
    "        out = out.to(\"cuda\")\n",
    "        return out\n",
    "lr = lr(2, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.forward(make_bow_vector(word_sents[0], vocab))\n",
    "lr = lr.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(model, word_sents, sentiment, vocab):\n",
    "    m = nn.LogSoftmax(dim=1)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    # See what the scores are before training\n",
    "    # Note that element i,j of the output is the score for tag j for word i.\n",
    "    # Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        first = make_bow_vector(word_sents[0], vocab)\n",
    "        first = first.to(\"cuda\")\n",
    "        scores = model(first)\n",
    "        print(scores)\n",
    "    p = 0\n",
    "    for epoch in range(2):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "        for i, rev in enumerate(word_sents[:49500]):\n",
    "            # Step 1. Remember that Pytorch accumulates gradients.\n",
    "            # We need to clear them out before each instance\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "            # Tensors of word indices.\n",
    "            bow_rev = make_bow_vector(rev, vocab)\n",
    "            target = torch.tensor([sentiment[i]])\n",
    "            target = target.to(\"cuda\")\n",
    "            bow_rev = bow_rev.to(\"cuda\")\n",
    "            # Step 3. Run our forward pass.\n",
    "            predict = model(bow_rev)\n",
    "            \n",
    "            \n",
    "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "            #  calling optimizer.step()\n",
    "            loss = loss_function(m(predict), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 495 == 0:\n",
    "                p+=1\n",
    "                print(\"loss:\", loss.item())\n",
    "                print(p,\"% ...\")\n",
    "train_lr(lr, word_sents, train_sent, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "#print(df.iloc[2][\"review\"])\n",
    "preds = list()\n",
    "for rev in word_sents[-500:]:\n",
    "    with torch.no_grad():\n",
    "        inp = make_bow_vector(rev, vocab)\n",
    "        inp = inp.to(\"cuda\")\n",
    "        out = lr(inp)\n",
    "        probs = torch.exp(m(out))\n",
    "        #print(probs)\n",
    "        #print(torch.argmax(probs, dim=1))\n",
    "        preds.append(torch.argmax(probs, dim=1)[0].item())\n",
    "        #print(\"gold: \", train_sent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds\n",
    "print(\"hej\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "golds = train_sent[-500:]\n",
    "preds\n",
    "golds = golds.astype(int)\n",
    "accuracy_score(golds, preds)\n",
    "cm = confusion_matrix(golds, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "accuracy_score(golds, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
